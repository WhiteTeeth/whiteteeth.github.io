<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.18.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="ios 11 新出了Vision 框架，提供了人脸识别、物体检测、物体跟踪等技术。本文将通过一个Demo简单介绍如何使用Vision框架进行物体检测和物体跟踪。本文Demo可以在Github上下载。">
<meta property="og:type" content="article">
<meta property="og:title" content="iOS 11 使用vision开始物体跟踪">
<meta property="og:url" content="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/index.html">
<meta property="og:site_name" content="Baiya&#39;s Blog">
<meta property="og:description" content="ios 11 新出了Vision 框架，提供了人脸识别、物体检测、物体跟踪等技术。本文将通过一个Demo简单介绍如何使用Vision框架进行物体检测和物体跟踪。本文Demo可以在Github上下载。">
<meta property="og:locale">
<meta property="og:image" content="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-f7e208ccc79f70b2.jpg">
<meta property="og:image" content="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-fd2d7f895427439e.jpg">
<meta property="og:image" content="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-804746537c671b3c.png">
<meta property="og:image" content="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-e38d98c0e1c18538.png">
<meta property="og:image" content="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-c3100d87d8966072.png">
<meta property="og:image" content="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-e8ead4ea31f0b1bf.png">
<meta property="article:published_time" content="2018-05-29T15:10:14.000Z">
<meta property="article:modified_time" content="2021-12-09T06:23:08.662Z">
<meta property="article:author" content="Baiya">
<meta property="article:tag" content="iOS">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-f7e208ccc79f70b2.jpg">


<link rel="canonical" href="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-Hans","comments":true,"permalink":"http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/","path":"2018/05/29/ios-11-使用vision开始物体跟踪/","title":"iOS 11 使用vision开始物体跟踪"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>iOS 11 使用vision开始物体跟踪 | Baiya's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Baiya's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E5%85%B3%E4%BA%8EVision%E6%A1%86%E6%9E%B6"><span class="nav-number">1.</span> <span class="nav-text">1. 关于Vision框架</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E4%BD%BF%E7%94%A8vision-%E8%BF%9B%E8%A1%8C%E7%89%A9%E4%BD%93%E8%AF%86%E5%88%AB"><span class="nav-number">2.</span> <span class="nav-text">2. 使用vision 进行物体识别</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83"><span class="nav-number">2.1.</span> <span class="nav-text">环境</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE"><span class="nav-number">2.2.</span> <span class="nav-text">获取图像数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B"><span class="nav-number">2.3.</span> <span class="nav-text">物体检测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%98%BE%E7%A4%BA%E6%A3%80%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="nav-number">2.4.</span> <span class="nav-text">显示检测结果</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA"><span class="nav-number">3.</span> <span class="nav-text">3. 物体跟踪</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%88%E6%9E%9C%E5%9B%BE"><span class="nav-number">3.1.</span> <span class="nav-text">效果图</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-%E6%80%A7%E8%83%BD"><span class="nav-number">4.</span> <span class="nav-text">4. 性能</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E6%9C%BA%E5%9E%8B"><span class="nav-number">4.1.</span> <span class="nav-text">测试机型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B-1"><span class="nav-number">4.2.</span> <span class="nav-text">物体检测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98"><span class="nav-number">4.2.1.</span> <span class="nav-text">内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%80%97%E6%97%B6"><span class="nav-number">4.2.2.</span> <span class="nav-text">耗时</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA"><span class="nav-number">4.3.</span> <span class="nav-text">物体跟踪</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98-1"><span class="nav-number">4.3.1.</span> <span class="nav-text">内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%80%97%E6%97%B6-1"><span class="nav-number">4.3.2.</span> <span class="nav-text">耗时</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-%E6%80%BB%E7%BB%93"><span class="nav-number">5.</span> <span class="nav-text">5. 总结</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E6%A1%A3"><span class="nav-number">5.1.</span> <span class="nav-text">参考文档</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Baiya</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/05/29/ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Baiya">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Baiya's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="iOS 11 使用vision开始物体跟踪 | Baiya's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          iOS 11 使用vision开始物体跟踪
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2018-05-29 23:10:14" itemprop="dateCreated datePublished" datetime="2018-05-29T23:10:14+08:00">2018-05-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-12-09 14:23:08" itemprop="dateModified" datetime="2021-12-09T14:23:08+08:00">2021-12-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>ios 11 新出了<a target="_blank" rel="noopener" href="https://developer.apple.com/documentation/vision">Vision</a> 框架，提供了人脸识别、物体检测、物体跟踪等技术。本文将通过一个Demo简单介绍如何使用Vision框架进行物体检测和物体跟踪。本文Demo可以在<a target="_blank" rel="noopener" href="https://github.com/WhiteTeeth/ios11-ObjectTrackDemo">Github</a>上下载。</p>
<span id="more"></span>

<h1 id="1-关于Vision框架"><a href="#1-关于Vision框架" class="headerlink" title="1. 关于Vision框架"></a>1. 关于Vision框架</h1><p>Vision 是伴随ios 11 推出的基于CoreML的图形处理框架。运用高性能图形处理和视觉技术，可以对图像和视频进行人脸检测、特征点检测和场景识别等。</p>
<p><img src="ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-f7e208ccc79f70b2.jpg" alt="img"></p>
<h1 id="2-使用vision-进行物体识别"><a href="#2-使用vision-进行物体识别" class="headerlink" title="2. 使用vision 进行物体识别"></a>2. 使用vision 进行物体识别</h1><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>Xcode 9 + ios 11</p>
<h2 id="获取图像数据"><a href="#获取图像数据" class="headerlink" title="获取图像数据"></a>获取图像数据</h2><p>该步骤假设你已经调起系统相机，并获得 <code>CMSampleBufferRef</code> 数据。注意返回的simpleBuffer 方向和UIView 显示方向不一致，所以先对simpleBuffer 旋转到正确的方向。</p>
<p>当然也可以不进行旋转，但是要保证后续坐标转换的一致性。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*</span><br><span class="line"> * 注意旋转SampleBuffer 为argb或者bgra格式，其他格式可能不支持</span><br><span class="line"> * rotationConstant:</span><br><span class="line"> *  0 -- rotate 0 degrees (simply copy the data from src to dest)</span><br><span class="line"> *  1 -- rotate 90 degrees counterclockwise</span><br><span class="line"> *  2 -- rotate 180 degress</span><br><span class="line"> *  3 -- rotate 270 degrees counterclockwise</span><br><span class="line"> */</span><br><span class="line">+ (CVPixelBufferRef)rotateBuffer:(CMSampleBufferRef)sampleBuffer withConstant:(uint8_t)rotationConstant</span><br><span class="line">&#123;</span><br><span class="line">    CVImageBufferRef imageBuffer        = CMSampleBufferGetImageBuffer(sampleBuffer);</span><br><span class="line">    CVPixelBufferLockBaseAddress(imageBuffer, 0);</span><br><span class="line">    </span><br><span class="line">    OSType pixelFormatType              = CVPixelBufferGetPixelFormatType(imageBuffer);</span><br><span class="line">    </span><br><span class="line">//    NSAssert(pixelFormatType == kCVPixelFormatType_32ARGB, @&quot;Code works only with 32ARGB format. Test/adapt for other formats!&quot;);</span><br><span class="line">    </span><br><span class="line">    const size_t kAlignment_32ARGB      = 32;</span><br><span class="line">    const size_t kBytesPerPixel_32ARGB  = 4;</span><br><span class="line">    </span><br><span class="line">    size_t bytesPerRow                  = CVPixelBufferGetBytesPerRow(imageBuffer);</span><br><span class="line">    size_t width                        = CVPixelBufferGetWidth(imageBuffer);</span><br><span class="line">    size_t height                       = CVPixelBufferGetHeight(imageBuffer);</span><br><span class="line">    </span><br><span class="line">    BOOL rotatePerpendicular            = (rotationConstant == 1) || (rotationConstant == 3); // Use enumeration values here</span><br><span class="line">    const size_t outWidth               = rotatePerpendicular ? height : width;</span><br><span class="line">    const size_t outHeight              = rotatePerpendicular ? width  : height;</span><br><span class="line">    </span><br><span class="line">    size_t bytesPerRowOut               = kBytesPerPixel_32ARGB * ceil(outWidth * 1.0 / kAlignment_32ARGB) * kAlignment_32ARGB;</span><br><span class="line">    </span><br><span class="line">    const size_t dstSize                = bytesPerRowOut * outHeight * sizeof(unsigned char);</span><br><span class="line">    </span><br><span class="line">    void *srcBuff                       = CVPixelBufferGetBaseAddress(imageBuffer);</span><br><span class="line">    </span><br><span class="line">    unsigned char *dstBuff              = (unsigned char *)malloc(dstSize);</span><br><span class="line">    </span><br><span class="line">    vImage_Buffer inbuff                = &#123;srcBuff, height, width, bytesPerRow&#125;;</span><br><span class="line">    vImage_Buffer outbuff               = &#123;dstBuff, outHeight, outWidth, bytesPerRowOut&#125;;</span><br><span class="line">    </span><br><span class="line">    uint8_t bgColor[4]                  = &#123;0, 0, 0, 0&#125;;</span><br><span class="line">    </span><br><span class="line">    vImage_Error err                    = vImageRotate90_ARGB8888(&amp;inbuff, &amp;outbuff, rotationConstant, bgColor, 0);</span><br><span class="line">    if (err != kvImageNoError)</span><br><span class="line">    &#123;</span><br><span class="line">        NSLog(@&quot;%ld&quot;, err);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    CVPixelBufferUnlockBaseAddress(imageBuffer, 0);</span><br><span class="line">    </span><br><span class="line">    CVPixelBufferRef rotatedBuffer      = NULL;</span><br><span class="line">    CVPixelBufferCreateWithBytes(NULL,</span><br><span class="line">                                 outWidth,</span><br><span class="line">                                 outHeight,</span><br><span class="line">                                 pixelFormatType,</span><br><span class="line">                                 outbuff.data,</span><br><span class="line">                                 bytesPerRowOut,</span><br><span class="line">                                 freePixelBufferDataAfterRelease,</span><br><span class="line">                                 NULL,</span><br><span class="line">                                 NULL,</span><br><span class="line">                                 &amp;rotatedBuffer);</span><br><span class="line">    </span><br><span class="line">    return rotatedBuffer;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void freePixelBufferDataAfterRelease(void *releaseRefCon, const void *baseAddress)</span><br><span class="line">&#123;</span><br><span class="line">    // Free the memory we malloced for the vImage rotation</span><br><span class="line">    free((void *)baseAddress);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="物体检测"><a href="#物体检测" class="headerlink" title="物体检测"></a>物体检测</h2><p>拿到图像数据后就可以进行物体检测，物体检测流程很简单：</p>
<ol>
<li>创建一个物体检测请求 VNDetectRectanglesRequest</li>
<li>根据数据源(pixelBuffer 或者 UIImage)创建一个 VNImageRequestHandler</li>
<li>调用[VNImageRequestHandler performRequests] 执行检测</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- (void)detectObjectWithPixelBuffer:(CVPixelBufferRef)pixelBuffer</span><br><span class="line">&#123;</span><br><span class="line">    CFAbsoluteTime start = CFAbsoluteTimeGetCurrent();</span><br><span class="line">    </span><br><span class="line">    void (^ VNRequestCompletionHandler)(VNRequest *request, NSError * _Nullable error) = ^(VNRequest *request, NSError * _Nullable error)</span><br><span class="line">    &#123;</span><br><span class="line">        CFAbsoluteTime end = CFAbsoluteTimeGetCurrent();</span><br><span class="line">        </span><br><span class="line">        NSLog(@&quot;检测耗时： %f&quot;, end - start);</span><br><span class="line">        if (!error &amp;&amp; request.results.count &gt; 0) &#123;</span><br><span class="line">            // TODO 这里处理检测结果</span><br><span class="line">            return ;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    VNImageRequestHandler *handler = [[VNImageRequestHandler alloc] initWithCVPixelBuffer:pixelBuffer options:@&#123;&#125;];</span><br><span class="line">    VNDetectRectanglesRequest *request = [[VNDetectRectanglesRequest alloc] initWithCompletionHandler:VNRequestCompletionHandler];</span><br><span class="line">    request.minimumAspectRatio = 0.1;	// 最小长宽比设为0.1</span><br><span class="line">    request.maximumObservations = 0;		// 不限制检测结果</span><br><span class="line">    [handler performRequests:@[request] error:nil];</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="显示检测结果"><a href="#显示检测结果" class="headerlink" title="显示检测结果"></a>显示检测结果</h2><p>物体检测返回结果是一个 <code>VNDetectedObjectObservation</code> 的结果集，包含<code>confidence</code>, <code>uuid</code> 和 <code>boundingBox</code>三种属性。 因为vision坐标系类似opengl的纹理坐标系，以屏幕左下角为坐标原点，并做了归一化。所以将显示结果投影到屏幕时，还需要进行坐标系的转换。</p>
<p>三种坐标系的区别：</p>
<table>
<thead>
<tr>
<th>坐标系</th>
<th>原点</th>
<th>长宽</th>
</tr>
</thead>
<tbody><tr>
<td>UIKit坐标系</td>
<td>左上角</td>
<td>屏幕大小</td>
</tr>
<tr>
<td>AVFoundation坐标系</td>
<td>左上角</td>
<td>0 - 1</td>
</tr>
<tr>
<td>Vision坐标系</td>
<td>左下角</td>
<td>0 - 1</td>
</tr>
</tbody></table>
<p>显示代码如下，使用<code>CGAffineTransform </code>进行坐标转换，并根据转换后矩形绘制红色边框。同时打印<code>confidence</code>信息到屏幕上。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- (void)overlayImageWithSize:(CGSize)size</span><br><span class="line">&#123;</span><br><span class="line">    </span><br><span class="line">    NSDictionary *lastObsercationDicCopy = [NSDictionary dictionaryWithDictionary:self.lastObsercationsDic];</span><br><span class="line">    NSArray *keyArr = [lastObsercationDicCopy allKeys];</span><br><span class="line">    </span><br><span class="line">    UIGraphicsImageRenderer *renderer = [[UIGraphicsImageRenderer alloc] initWithSize:CGSizeMake(size.width, size.height)];</span><br><span class="line">    </span><br><span class="line">    void (^UIGraphicsImageDrawingActions)(UIGraphicsImageRendererContext *rendererContext) = ^(UIGraphicsImageRendererContext *rendererContext)</span><br><span class="line">    &#123;</span><br><span class="line">    	 // 将vision坐标转换为屏幕坐标</span><br><span class="line">        CGAffineTransform  transform = CGAffineTransformIdentity;</span><br><span class="line">        transform = CGAffineTransformScale(transform, size.width, -size.height);</span><br><span class="line">        transform = CGAffineTransformTranslate(transform, 0, -1);</span><br><span class="line">        </span><br><span class="line">        for (NSString *uuid in keyArr) &#123;</span><br><span class="line">            VNDetectedObjectObservation *rectangleObservation = lastObsercationDicCopy[uuid];</span><br><span class="line">            </span><br><span class="line">            // 绘制红框</span><br><span class="line">            [[UIColor redColor] setStroke];</span><br><span class="line">            UIBezierPath *path = [UIBezierPath bezierPathWithRect:CGRectApplyAffineTransform(rectangleObservation.boundingBox, transform)];</span><br><span class="line">            path.lineWidth = 4.0f;</span><br><span class="line">            [path stroke];</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    UIImage *overlayImage = [renderer imageWithActions:UIGraphicsImageDrawingActions];</span><br><span class="line">    </span><br><span class="line">    NSMutableString *trackInfoStr = [NSMutableString string];</span><br><span class="line">    </span><br><span class="line">    for (NSString *uuid in keyArr) &#123;</span><br><span class="line">        VNDetectedObjectObservation *rectangleObservation = lastObsercationDicCopy[uuid];</span><br><span class="line">        </span><br><span class="line">        [trackInfoStr appendFormat:@&quot;置信度 ： %.2f \n&quot;, rectangleObservation.confidence];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    dispatch_async(dispatch_get_main_queue(), ^&#123;</span><br><span class="line">        </span><br><span class="line">        self.highlightView.image = overlayImage;</span><br><span class="line">        </span><br><span class="line">        self.infoLabel.text = trackInfoStr;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;   </span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="3-物体跟踪"><a href="#3-物体跟踪" class="headerlink" title="3. 物体跟踪"></a>3. 物体跟踪</h1><p>物体跟踪需要处理连续的视频帧，所以需要创建<code>VNSequenceRequestHandler</code>处理多帧图像。同时还需要一个<code>VNDetectedObjectObservation</code>对象 做为参考源。你可以使用物体检测的结果，或者指定一个矩形作为物体跟踪的参考源。注意因为坐标系不同，如果直接指定矩形作为参考源时，需要事先进行正确的坐标转换。</p>
<p>跟踪多物体时，可以使用<code>VNDetectedObjectObservation.uuid</code>区分跟踪对象，并做相应处理。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- (void)objectTrackWithPixelBuffer:(CVPixelBufferRef)pixelBuffer</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    if (!self.sequenceHandler) &#123;</span><br><span class="line">        self.sequenceHandler = [[VNSequenceRequestHandler alloc] init];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    NSArray&lt;NSString *&gt; *obsercationKeys = self.lastObsercationsDic.allKeys;</span><br><span class="line">    </span><br><span class="line">    NSMutableArray&lt;VNTrackObjectRequest *&gt; *obsercationRequest = [NSMutableArray array];</span><br><span class="line">    </span><br><span class="line">    CFAbsoluteTime start = CFAbsoluteTimeGetCurrent();</span><br><span class="line">    for (NSString *key in obsercationKeys) &#123;</span><br><span class="line">        </span><br><span class="line">        VNDetectedObjectObservation *obsercation = self.lastObsercationsDic[key];</span><br><span class="line">        </span><br><span class="line">        VNTrackObjectRequest *trackObjectRequest = [[VNTrackObjectRequest alloc] initWithDetectedObjectObservation:obsercation completionHandler:^(VNRequest * _Nonnull request, NSError * _Nullable error) &#123;</span><br><span class="line">            </span><br><span class="line">            CFAbsoluteTime end = CFAbsoluteTimeGetCurrent();</span><br><span class="line">            NSLog(@&quot;跟踪耗时： %f&quot;, end - start);</span><br><span class="line">            </span><br><span class="line">            if (nil == error &amp;&amp; request.results.count &gt; 0) &#123;</span><br><span class="line">                </span><br><span class="line">                // TODO 处理跟踪结果</span><br><span class="line">                </span><br><span class="line">                </span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // 跟踪失败处理</span><br><span class="line">                </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;];</span><br><span class="line">        trackObjectRequest.trackingLevel = VNRequestTrackingLevelAccurate;</span><br><span class="line">        </span><br><span class="line">        [obsercationRequest addObject:trackObjectRequest];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    NSError *error = nil;</span><br><span class="line">    [self.sequenceHandler performRequests:obsercationRequest onCVPixelBuffer:pixelBuffer error:&amp;error];</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h2><p><img src="ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-fd2d7f895427439e.jpg" alt="img"></p>
<h1 id="4-性能"><a href="#4-性能" class="headerlink" title="4. 性能"></a>4. 性能</h1><h2 id="测试机型"><a href="#测试机型" class="headerlink" title="测试机型"></a>测试机型</h2><p>iphone6p ios 11.0(15A5318g)</p>
<p>1/10 取帧率</p>
<h2 id="物体检测-1"><a href="#物体检测-1" class="headerlink" title="物体检测"></a>物体检测</h2><h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>稳定在40M左右</p>
<p><img src="ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-804746537c671b3c.png" alt="img"></p>
<h3 id="耗时"><a href="#耗时" class="headerlink" title="耗时"></a>耗时</h3><p>平均在50ms左右</p>
<p><img src="ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-e38d98c0e1c18538.png" alt="img"></p>
<h2 id="物体跟踪"><a href="#物体跟踪" class="headerlink" title="物体跟踪"></a>物体跟踪</h2><h3 id="内存-1"><a href="#内存-1" class="headerlink" title="内存"></a>内存</h3><p>和物体检测一样在40M左右</p>
<p><img src="ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-c3100d87d8966072.png" alt="img"></p>
<h3 id="耗时-1"><a href="#耗时-1" class="headerlink" title="耗时"></a>耗时</h3><p>相对低些，20-40ms不等</p>
<p><img src="ios-11-%E4%BD%BF%E7%94%A8vision%E5%BC%80%E5%A7%8B%E7%89%A9%E4%BD%93%E8%B7%9F%E8%B8%AA/6357961-e8ead4ea31f0b1bf.png" alt="img"></p>
<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h1><p>Vision是一个比较好用的框架，性能也不错。除了物体跟踪，Vision还提供<strong>图像分类</strong>、<strong>人脸识别</strong>、<strong>人脸特征提取</strong>、<strong>人脸追踪</strong>、<strong>文字识别</strong>等功能，使用方法和物体检测类似，本文就不再进行过多描述。</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a target="_blank" rel="noopener" href="https://github.com/jeffreybergier/Blog-Getting-Started-with-Vision">Getting Started with Vision</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/iOS/" rel="tag"># iOS</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2018/05/29/ios-%E5%88%9B%E5%BB%BA%E5%9F%BA%E4%BA%8E%E4%BA%BA%E8%84%B8%E7%9A%84AR%E5%BA%94%E7%94%A8/" rel="prev" title="iOS 创建基于人脸的AR应用">
                  <i class="fa fa-angle-left"></i> iOS 创建基于人脸的AR应用
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2018/05/29/ios-%E6%BB%A4%E9%95%9C%E4%B9%8BCIBlendWithAlphaMask%E5%9C%A8%E7%89%B9%E6%AE%8A%E7%B3%BB%E7%BB%9F%E6%B8%B2%E6%9F%93%E5%A4%B1%E8%B4%A5%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" rel="next" title="iOS 滤镜之CIBlendWithAlphaMask在特殊系统渲染失败的解决方案">
                  iOS 滤镜之CIBlendWithAlphaMask在特殊系统渲染失败的解决方案 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Baiya</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":null,"repo":null,"client_id":null,"client_secret":null,"admin_user":null,"distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"49f3bb55701ed3a7c6bd23a6672b7a1d"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
